{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:42:16.424334Z",
     "start_time": "2020-10-05T12:42:14.573017Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from src.constants import DATA_PATH, MASTER_THESIS_DIR, TRAINING_CONFIG_PATH, MODEL_CONFIG_PATH\n",
    "from src.data_loader.data_set import Data_Set\n",
    "from src.experiments.utils import get_experiement_args, process_experiment_args\n",
    "from src.models.baseline_model import BaselineModel\n",
    "from src.utils import get_console_logger, read_json\n",
    "from src.visualization.visualize import plot_hand\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from easydict import EasyDict as edict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:42:16.448741Z",
     "start_time": "2020-10-05T12:42:16.442593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 5, 'gpu': False, 'resnet_trainable': True, 'learning_rate': 0.0001, 'scheduler': {'choice': 'cosine_annealing', 'cosine_annealing': {'T_max': 20, 'verbose': True}, 'reduce_on_plateau': {'mode': 'min', 'factor': 0.5, 'patience': 4, 'verbose': True}}}\n"
     ]
    }
   ],
   "source": [
    "model_config = edict(read_json(MODEL_CONFIG_PATH))\n",
    "model_config.gpu =False\n",
    "train_config =  edict(read_json(TRAINING_CONFIG_PATH))\n",
    "train_config.crop =True\n",
    "train_config.rotate=True\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:42:18.240627Z",
     "start_time": "2020-10-05T12:42:16.475682Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = Data_Set(\n",
    "    config=train_config,\n",
    "    transforms=transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ),\n",
    "    train_set=True,\n",
    ")\n",
    "val_data = copy.copy(train_data)\n",
    "val_data.is_training(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:42:18.509159Z",
     "start_time": "2020-10-05T12:42:18.262943Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BaselineModel(config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:42:19.221162Z",
     "start_time": "2020-10-05T12:42:19.047592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaselineModel(\n",
       "  (resnet18): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (layer_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (output_layer): Linear(in_features=128, out_features=63, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(os.path.join(MASTER_THESIS_DIR,\"models\",\"master-thesis\",\"30a940c759aa43f1b19e22ecfff1621e\",\"checkpoints\",\"epoch=99.ckpt\"), map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:42:21.107713Z",
     "start_time": "2020-10-05T12:42:20.748466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58948adf90a34ae2a95838e175cfd486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='idx', min=1, step=5), Output()), _dom_classes=('widget-iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(idx=widgets.IntSlider(min=1, max=100, step=5, value=3))\n",
    "def visualize(idx):\n",
    "    sample = val_data[idx]\n",
    "    joints = sample[\"joints\"]\n",
    "    img = sample[\"image\"]\n",
    "    img_input = img.view(([1]+list(img.shape)))\n",
    "    prediction = model(img_input).view(21,3).detach().numpy()\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.imshow(transforms.ToPILImage()(img))\n",
    "#     plot_hand(ax, joints)\n",
    "    plot_hand(ax, prediction,linestyle=':' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:48:26.145819Z",
     "start_time": "2020-10-05T12:48:22.139391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fb512976e543288584b96a23a15226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=130.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_pred_2d = []\n",
    "val_pred_z = []\n",
    "val_gt_z = []\n",
    "val_gt_2d =[]\n",
    "for i in tqdm(range(len(val_data)//100)):\n",
    "    sample =train_data[i]\n",
    "    joints = sample[\"joints\"]\n",
    "    img = sample[\"image\"]\n",
    "    img_input = img.view(([1]+list(img.shape)))\n",
    "    pred = model(img_input).view(21,3)\n",
    "    val_pred_2d.append(pred[:,:-1])\n",
    "    val_pred_z.append(pred[:,-1:])\n",
    "    val_gt_z.append(joints[:,-1:])\n",
    "    val_gt_2d.append(joints[:,:-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:44:47.709089Z",
     "start_time": "2020-10-05T12:44:47.686609Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class EvalUtil:\n",
    "    \"\"\" Util class for evaluation networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_kp=21):\n",
    "        # init empty data storage\n",
    "        self.data = list()\n",
    "        self.num_kp = num_kp\n",
    "        for _ in range(num_kp):\n",
    "            self.data.append(list())\n",
    "\n",
    "    def feed(self, keypoint_gt, keypoint_vis, keypoint_pred, skip_check=False):\n",
    "        \"\"\" Used to feed data to the class. Stores the euclidean distance between gt and pred, when it is visible. \"\"\"\n",
    "        if not skip_check:\n",
    "            keypoint_gt = np.squeeze(keypoint_gt)\n",
    "            keypoint_pred = np.squeeze(keypoint_pred)\n",
    "            keypoint_vis = np.squeeze(keypoint_vis).astype('bool')\n",
    "\n",
    "            assert len(keypoint_gt.shape) == 2\n",
    "            assert len(keypoint_pred.shape) == 2\n",
    "            assert len(keypoint_vis.shape) == 1\n",
    "\n",
    "        # calc euclidean distance\n",
    "        diff = keypoint_gt - keypoint_pred\n",
    "        euclidean_dist = np.sqrt(np.sum(np.square(diff), axis=1))\n",
    "\n",
    "        num_kp = keypoint_gt.shape[0]\n",
    "        for i in range(num_kp):\n",
    "            if keypoint_vis[i]:\n",
    "                self.data[i].append(euclidean_dist[i])\n",
    "\n",
    "    def _get_pck(self, kp_id, threshold):\n",
    "        \"\"\" Returns pck for one keypoint for the given threshold. \"\"\"\n",
    "        if len(self.data[kp_id]) == 0:\n",
    "            return None\n",
    "\n",
    "        data = np.array(self.data[kp_id])\n",
    "        pck = np.mean((data <= threshold).astype('float'))\n",
    "        return pck\n",
    "\n",
    "    def _get_epe(self, kp_id):\n",
    "        \"\"\" Returns end point error for one keypoint. \"\"\"\n",
    "        if len(self.data[kp_id]) == 0:\n",
    "            return None, None\n",
    "\n",
    "        data = np.array(self.data[kp_id])\n",
    "        epe_mean = np.mean(data)\n",
    "        epe_median = np.median(data)\n",
    "        return epe_mean, epe_median\n",
    "\n",
    "    def get_measures(self, val_min, val_max, steps):\n",
    "        \"\"\" Outputs the average mean and median error as well as the pck score. \"\"\"\n",
    "        thresholds = np.linspace(val_min, val_max, steps)\n",
    "        thresholds = np.array(thresholds)\n",
    "        norm_factor = np.trapz(np.ones_like(thresholds), thresholds)\n",
    "\n",
    "        # init mean measures\n",
    "        epe_mean_all = list()\n",
    "        epe_median_all = list()\n",
    "        auc_all = list()\n",
    "        pck_curve_all = list()\n",
    "\n",
    "        # Create one plot for each part\n",
    "        for part_id in range(self.num_kp):\n",
    "            # mean/median error\n",
    "            mean, median = self._get_epe(part_id)\n",
    "\n",
    "            if mean is None:\n",
    "                # there was no valid measurement for this keypoint\n",
    "                continue\n",
    "\n",
    "            epe_mean_all.append(mean)\n",
    "            epe_median_all.append(median)\n",
    "\n",
    "            # pck/auc\n",
    "            pck_curve = list()\n",
    "            for t in thresholds:\n",
    "                pck = self._get_pck(part_id, t)\n",
    "                pck_curve.append(pck)\n",
    "\n",
    "            pck_curve = np.array(pck_curve)\n",
    "            pck_curve_all.append(pck_curve)\n",
    "            auc = np.trapz(pck_curve, thresholds)\n",
    "            auc /= norm_factor\n",
    "            auc_all.append(auc)\n",
    "\n",
    "        epe_mean_all = np.mean(np.array(epe_mean_all))\n",
    "        epe_median_all = np.mean(np.array(epe_median_all))\n",
    "        auc_all = np.mean(np.array(auc_all))\n",
    "        pck_curve_all = np.mean(np.array(pck_curve_all), 0)  # mean only over keypoints\n",
    "\n",
    "        return epe_mean_all, epe_median_all, auc_all, pck_curve_all, thresholds\n",
    "\n",
    "eval = EvalUtil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:48:30.825153Z",
     "start_time": "2020-10-05T12:48:30.819220Z"
    }
   },
   "outputs": [],
   "source": [
    "eval.feed(val_gt_2d[0].detach().numpy(), np.ones(21), val_pred_2d[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:48:31.403797Z",
     "start_time": "2020-10-05T12:48:31.388776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.2212625,\n",
       " 4.2212625,\n",
       " 0.6547619047619045,\n",
       " array([0.04761905, 0.14285714, 0.42857143, 0.57142857, 0.69047619,\n",
       "        0.78571429, 0.88095238, 0.92857143, 0.95238095, 0.97619048]),\n",
       " array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.get_measures(1,10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
