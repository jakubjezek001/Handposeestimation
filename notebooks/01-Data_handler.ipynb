{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "   <center><font size=\"8\">Data visualization</font></center>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T18:01:27.331365Z",
     "start_time": "2021-01-13T18:01:26.292719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data_loader.data_set import Data_Set\n",
    "from src.data_loader.utils import get_train_val_split\n",
    "from src.constants import MASTER_THESIS_DIR, FREIHAND_DATA\n",
    "from src.utils import read_json\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive,GridspecLayout, interact\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import copy\n",
    "from easydict import EasyDict as edict\n",
    "from src.utils import read_json\n",
    "from src.visualization.visualize import plot_hand\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T18:01:28.822748Z",
     "start_time": "2021-01-13T18:01:27.356755Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "train_param = edict(\n",
    "    read_json(f\"{MASTER_THESIS_DIR}/src/experiments/config/training_config.json\")\n",
    ")\n",
    "train_data = None\n",
    "@interact(\n",
    "    source=widgets.Dropdown(\n",
    "        options=[\"interhand\", \"freihand\", \"youtube\"],\n",
    "        value=\"youtube\",\n",
    "        description=\"source\",\n",
    "        disabled=False,\n",
    "    )\n",
    ")\n",
    "def select_data(source):\n",
    "    global train_data\n",
    "    train_data = Data_Set(\n",
    "        config=train_param,\n",
    "        transform=transforms.ToTensor(),\n",
    "        train_set=False,\n",
    "        experiment_type=\"supervised\",\n",
    "        source=source,\n",
    "    )\n",
    "    \n",
    "val_data = copy.copy(train_data)\n",
    "val_data.is_training(False)\n",
    "\n",
    "# train_data_loader, val_data_loader = get_train_val_split(\n",
    "#     train_data,\n",
    "#     batch_size=train_param.batch_size,\n",
    "#     num_workers=train_param.num_workers,\n",
    "# )\n",
    "params = {\n",
    "    \"ytick.color\": \"w\",\n",
    "    \"xtick.color\": \"w\",\n",
    "    \"axes.labelcolor\": \"w\",\n",
    "    \"axes.edgecolor\": \"w\",\n",
    "    \"text.color\": \"w\",\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "font_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T18:01:28.925050Z",
     "start_time": "2021-01-13T18:01:28.851684Z"
    },
    "cell_style": "center",
    "code_folding": [
     0,
     13,
     39,
     75,
     89,
     112,
     117,
     126,
     149,
     192,
     212,
     261
    ]
   },
   "outputs": [],
   "source": [
    "def visualize(\n",
    "    idx,\n",
    "    experiment_type,\n",
    "    random_crop,\n",
    "    crop,\n",
    "    color_jitter,\n",
    "    cut_out,\n",
    "    resize,\n",
    "    color_drop,\n",
    "    rotate,\n",
    "    gaussian_blur,\n",
    "    gaussian_noise,\n",
    "    sobel_filter,\n",
    "):\n",
    "    train_param.augmentation_flags.random_crop = random_crop\n",
    "    train_param.augmentation_flags.crop = crop\n",
    "    train_param.augmentation_flags.color_jitter = color_jitter\n",
    "    train_param.augmentation_flags.cut_out = cut_out\n",
    "    train_param.augmentation_flags.resize = resize\n",
    "    train_param.augmentation_flags.color_drop = color_drop\n",
    "    train_param.augmentation_flags.gaussian_blur = gaussian_blur\n",
    "    train_param.augmentation_flags.rotate = rotate\n",
    "    train_param.augmentation_flags.sobel_filter = sobel_filter\n",
    "    train_param.augmentation_flags.gaussian_noise = gaussian_noise\n",
    "    #     train_param.augmentation_params.crop_margin_range = [\n",
    "    #         crop_margin_range / 100.0,\n",
    "    #         crop_margin_range / 100.0,\n",
    "    #     ]\n",
    "    #     train_param.augmentation_params.cut_out_fraction = [\n",
    "    #         cut_out_fraction / 100.0,\n",
    "    #         cut_out_fraction / 100.0,\n",
    "    #     ]\n",
    "    #     train_param.augmentation_params.hue_factor_range=[hue_factor_range/100.0,hue_factor_range/100.0]\n",
    "    #     train_param.augmentation_params.sat_factor_range=[sat_factor_range/100.0,sat_factor_range/100.0]\n",
    "    #     train_param.augmentation_params.value_factor_beta_range= [value_factor_beta_range/100.0,value_factor_beta_range/100.0]\n",
    "    #     train_param.augmentation_params.value_factor_alpha_range= [value_factor_alpha_range/100.0 ,value_factor_alpha_range/100.0]\n",
    "    train_data.augmenter = train_data.get_sample_augmenter(\n",
    "        train_param.augmentation_params, train_param.augmentation_flags\n",
    "    )\n",
    "    if experiment_type == \"supervised\":\n",
    "        train_data.experiment_type = \"supervised\"\n",
    "        sample = train_data[idx]\n",
    "        joints = sample[\"joints\"]\n",
    "        img = torch.flip(sample[\"image\"], (0,))\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "        ax = fig.add_subplot(121)\n",
    "        plt.imshow(transforms.ToPILImage()(img))\n",
    "        plot_hand(ax, joints)\n",
    "        ax = fig.add_subplot(122, projection=\"3d\")\n",
    "        ax.set_facecolor(\"black\")\n",
    "        plot_hand(\n",
    "            ax,\n",
    "            sample[\"joints3D\"],\n",
    "            plot_3d=True,\n",
    "            alpha=0.2,\n",
    "            linestyle=\"-\",\n",
    "            linewidth=\"5\",\n",
    "        )\n",
    "        plot_hand(\n",
    "            ax,\n",
    "            sample[\"joints3D_recreated\"],\n",
    "            plot_3d=True,\n",
    "            linestyle=\":\",\n",
    "        )\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Max Error recreated 3D\": [\n",
    "                        torch.max(\n",
    "                            sample[\"joints3D\"] - sample[\"joints3D_recreated\"]\n",
    "                        ).numpy()\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    elif experiment_type == \"simclr\":\n",
    "        train_data.experiment_type = \"simclr\"\n",
    "        sample = train_data[idx]\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "        ax = fig.add_subplot(121)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(torch.flip(sample[\"transformed_image1\"], (0,)))\n",
    "        )\n",
    "        ax.set_title(\"Image 1\")\n",
    "        ax = fig.add_subplot(122)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(torch.flip(sample[\"transformed_image2\"], (0,)))\n",
    "        )\n",
    "        ax.set_title(\"Image 2\")\n",
    "    elif experiment_type == \"pairwise\":\n",
    "        train_data.experiment_type = \"pairwise\"\n",
    "        sample = train_data[idx]\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "        ax = fig.add_subplot(121)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(torch.flip(sample[\"transformed_image1\"], (0,)))\n",
    "        )\n",
    "        ax.set_title(\"Image 1\")\n",
    "        ax = fig.add_subplot(122)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(torch.flip(sample[\"transformed_image2\"], (0,)))\n",
    "        )\n",
    "        ax.set_title(\"Image 2\")\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    k: [v.numpy()]\n",
    "                    for k, v in sample.items()\n",
    "                    if \"image\" not in k and \"joints\" not in k\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    elif experiment_type == \"experiment4_pretraining\":\n",
    "        train_data.experiment_type = \"experiment4_pretraining\"\n",
    "        sample = train_data[idx]\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "        ax = fig.add_subplot(121)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(torch.flip(sample[\"transformed_image1\"], (0,)))\n",
    "        )\n",
    "        ax.set_title(\"Image 1\")\n",
    "        ax = fig.add_subplot(122)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(torch.flip(sample[\"transformed_image2\"], (0,)))\n",
    "        )\n",
    "        ax.set_title(\"Image 2\")\n",
    "    elif experiment_type == \"pairwise_ablative\":\n",
    "        train_data.experiment_type = \"pairwise_ablative\"\n",
    "        sample = train_data[idx]\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "        ax = fig.add_subplot(121)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(torch.flip(sample[\"transformed_image1\"], (0,)))\n",
    "        )\n",
    "        ax.set_title(\"Image 1\")\n",
    "        ax = fig.add_subplot(122)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(torch.flip(sample[\"transformed_image2\"], (0,)))\n",
    "        )\n",
    "        ax.set_title(\"Image 2\")\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    k: [v.numpy()]\n",
    "                    for k, v in sample.items()\n",
    "                    if \"image\" not in k and \"joints\" not in k\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    elif experiment_type == \"hybrid1\":\n",
    "        train_data.experiment_type = \"hybrid1\"\n",
    "        train_data.pairwise_augmenter = train_data.augmenter\n",
    "        train_data.contrastive_augmenter = train_data.augmenter\n",
    "        sample = train_data[idx]\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_subplot(221)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(\n",
    "                torch.flip(sample[\"pairwise\"][\"transformed_image1\"], (0,))\n",
    "            )\n",
    "        )\n",
    "        ax.set_title(\"Pairwise: Image 1\")\n",
    "        ax = fig.add_subplot(222)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(\n",
    "                torch.flip(sample[\"pairwise\"][\"transformed_image2\"], (0,))\n",
    "            )\n",
    "        )\n",
    "        ax.set_title(\"Pairwise: Image 2\")\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    k: [v.numpy()]\n",
    "                    for k, v in sample[\"pairwise\"].items()\n",
    "                    if \"image\" not in k and \"joints\" not in k\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        ax = fig.add_subplot(223)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(\n",
    "                torch.flip(sample[\"contrastive\"][\"transformed_image1\"], (0,))\n",
    "            )\n",
    "        )\n",
    "        ax.set_title(\"Contrastive: Image 1\")\n",
    "        ax = fig.add_subplot(224)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(\n",
    "                torch.flip(sample[\"contrastive\"][\"transformed_image2\"], (0,))\n",
    "            )\n",
    "        )\n",
    "        ax.set_title(\"Contrastive: Image 2\")\n",
    "    elif experiment_type == \"hybrid2\":\n",
    "        train_data.experiment_type = \"hybrid2\"\n",
    "        sample = train_data[idx]\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "        ax = fig.add_subplot(121)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(torch.flip(sample[\"transformed_image1\"], (0,)))\n",
    "        )\n",
    "        title1 = {k:v for k,v in sample.items() if (('image' not in k) and ('1' in k))}\n",
    "        ax.set_title(f\"Image 1 : \\n {title1}\")\n",
    "        ax = fig.add_subplot(122)\n",
    "        plt.imshow(\n",
    "            transforms.ToPILImage()(torch.flip(sample[\"transformed_image2\"], (0,)))\n",
    "        )\n",
    "        title2 = {k:v for k,v in sample.items() if (('image' not in k) and ('2' in k))}\n",
    "        ax.set_title(f\"Image 1 : \\n {title2}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "visualization_panel = interactive(\n",
    "    visualize,\n",
    "    idx=widgets.IntSlider(min=1, max=3000, step=5, value=3),\n",
    "    experiment_type=widgets.Dropdown(\n",
    "        options=[\n",
    "            \"supervised\",\n",
    "            \"simclr\",\n",
    "            \"pairwise\",\n",
    "            \"experiment4_pretraining\",\n",
    "            \"pairwise_ablative\",\n",
    "            \"hybrid1\",\n",
    "            \"hybrid2\",\n",
    "        ],\n",
    "        value=\"pairwise\",\n",
    "        description=f\"<font size='{font_size}'>Model</font>\",\n",
    "        disabled=False,\n",
    "    ),\n",
    "    random_crop=widgets.Checkbox(\n",
    "        value=False, description=f\"<font size='{font_size}'>Random crop</font>\"\n",
    "    ),\n",
    "    crop=widgets.Checkbox(\n",
    "        value=True, description=f\"<font size='{font_size}'>Crop</font>\"\n",
    "    ),\n",
    "    color_jitter=widgets.Checkbox(\n",
    "        value=False, description=f\"<font size='{font_size}'>Color jitter</font>\"\n",
    "    ),\n",
    "    cut_out=widgets.Checkbox(\n",
    "        value=False, description=f\"<font size='{font_size}'>Cut out</font>\"\n",
    "    ),\n",
    "    resize=widgets.Checkbox(\n",
    "        value=True, description=f\"<font size='{font_size}'>Resize</font>\"\n",
    "    ),\n",
    "    color_drop=widgets.Checkbox(\n",
    "        value=False, description=f\"<font size='{font_size}'>Color drop</font>\"\n",
    "    ),\n",
    "    rotate=widgets.Checkbox(\n",
    "        value=False, description=f\"<font size='{font_size}'>Rotate</font>\"\n",
    "    ),\n",
    "    gaussian_blur=widgets.Checkbox(\n",
    "        value=False, description=f\"<font size='{font_size}'>Blur(gaussian)</font>\"\n",
    "    ),\n",
    "    gaussian_noise=widgets.Checkbox(\n",
    "        value=False, description=f\"<font size='{font_size}'>Noise(gaussian)</font>\"\n",
    "    ),\n",
    "    sobel_filter=widgets.Checkbox(\n",
    "        value=False, description=f\"<font size='{font_size}'>sobel_filter</font>\"\n",
    "    ),\n",
    ")\n",
    "augmentation_checkboxes = visualization_panel.children[:-1]\n",
    "grid = GridspecLayout(\n",
    "    22,\n",
    "    6,\n",
    ")\n",
    "grid[0, 1] = visualization_panel.children[0]\n",
    "visualization_panel.children[0].description = f\"<font size='{font_size}'>Index</font>\"\n",
    "grid[0, 3] = visualization_panel.children[1]\n",
    "count = 2\n",
    "for i in range(2, 4):\n",
    "    for j in range(5):\n",
    "        grid[i, j] = augmentation_checkboxes[count]\n",
    "        count += 1\n",
    "grid[4:, 1:] = visualization_panel.children[-1]\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T01:09:46.173643Z",
     "start_time": "2020-12-03T01:09:46.168014Z"
    },
    "cell_style": "split",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Visualize sample in batch\n",
    "# @interact(\n",
    "#     idx=widgets.IntSlider(min=0, max=31, step=1, value=10),\n",
    "#     experiment_type=widgets.Dropdown(\n",
    "#         options=[\"supervised\", \"simclr\", \"pairwise\"],\n",
    "#         value=\"pairwise\",\n",
    "#         description=\"Experiment type:\",\n",
    "#         disabled=False,\n",
    "#     ),\n",
    "# )\n",
    "# def vis(idx, experiment_type):\n",
    "#     train_data.experiment_type = experiment_type\n",
    "#     for i, elem in enumerate(train_data_loader):\n",
    "#         if experiment_type == \"supervised\":\n",
    "#             sample = elem\n",
    "#             joints = sample[\"joints\"][idx]\n",
    "#             img = sample[\"image\"][idx]\n",
    "#             fig = plt.figure(figsize=(5, 5))\n",
    "#             ax = fig.add_subplot(111)\n",
    "#             plt.imshow(transforms.ToPILImage()(img))\n",
    "#             plot_hand(ax, joints)\n",
    "#             plt.show()\n",
    "#         elif experiment_type == \"simclr\":\n",
    "#             sample = elem\n",
    "#             fig = plt.figure(figsize=(10, 10))\n",
    "#             ax = fig.add_subplot(121)\n",
    "#             plt.imshow(transforms.ToPILImage()(sample[\"transformed_image1\"][idx]))\n",
    "#             ax.set_title(\"Image 1\")\n",
    "#             ax = fig.add_subplot(122)\n",
    "#             plt.imshow(transforms.ToPILImage()(sample[\"transformed_image2\"][idx]))\n",
    "#             ax.set_title(\"Image 2\")\n",
    "#         elif experiment_type == \"pairwise\":\n",
    "#             train_data.experiment_type = \"pairwise\"\n",
    "#             sample = train_data[idx]\n",
    "#             fig = plt.figure(figsize=(10, 10))\n",
    "#             ax = fig.add_subplot(121)\n",
    "#             plt.imshow(transforms.ToPILImage()(sample[\"transformed_image1\"]))\n",
    "#             ax.set_title(\"Image 1\")\n",
    "#             ax = fig.add_subplot(122)\n",
    "#             plt.imshow(transforms.ToPILImage()(sample[\"transformed_image2\"]))\n",
    "#             ax.set_title(\"Image 2\")\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "396px",
    "left": "1027px",
    "right": "20px",
    "top": "109px",
    "width": "708px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
